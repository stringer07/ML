{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1]) torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "primelist=[]\n",
    "for i in range(1,1001):\n",
    "    primelist.append(sympy.prime(i))\n",
    "x1=torch.tensor(primelist)[:,np.newaxis]\n",
    "y1=torch.ones(1000,1)\n",
    "print(np.shape(x1),np.shape(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1]) torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "nonprimelist=[]\n",
    "for i in range(1,100000):\n",
    "    if not sympy.isprime(i):\n",
    "        nonprimelist.append(i)\n",
    "    if len(nonprimelist)==1000:\n",
    "        break\n",
    "x2=torch.tensor(nonprimelist)[:,np.newaxis]\n",
    "y2=torch.zeros(1000,1)\n",
    "print(np.shape(x2),np.shape(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.cat((x1,x2),dim=0).type(torch.FloatTensor)\n",
    "y=torch.cat((y1,y2),dim=0).squeeze().long()\n",
    "x,y=Variable(x),Variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.layer1=nn.Sequential(nn.Linear(1,64),nn.Dropout(p=0.1),nn.LeakyReLU())\n",
    "        self.layer2=nn.Sequential(nn.Linear(64,64),nn.Dropout(p=0.1),nn.LeakyReLU())\n",
    "        self.layer3=nn.Sequential(nn.Linear(64,2),nn.LeakyReLU())\n",
    "    def forward(self,x):\n",
    "        #x=x.view(x.size()[0],-1)\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        return x\n",
    "net=Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.267576, auc: 0.9010\n",
      "epoch: 400, loss: 0.287963, auc: 0.8980\n",
      "epoch: 800, loss: 0.270863, auc: 0.9005\n",
      "epoch: 1200, loss: 0.269221, auc: 0.9010\n",
      "epoch: 1600, loss: 0.269241, auc: 0.9000\n",
      "epoch: 2000, loss: 0.270819, auc: 0.9015\n",
      "epoch: 2400, loss: 0.270131, auc: 0.9005\n",
      "epoch: 2800, loss: 0.269252, auc: 0.9005\n",
      "epoch: 3200, loss: 0.270378, auc: 0.9010\n",
      "epoch: 3600, loss: 0.268619, auc: 0.9000\n",
      "epoch: 4000, loss: 0.270105, auc: 0.9005\n",
      "epoch: 4400, loss: 0.271660, auc: 0.9005\n",
      "epoch: 4800, loss: 0.266402, auc: 0.9030\n",
      "epoch: 5200, loss: 0.269174, auc: 0.8990\n",
      "epoch: 5600, loss: 0.273309, auc: 0.9005\n",
      "epoch: 6000, loss: 0.266994, auc: 0.9005\n",
      "epoch: 6400, loss: 0.267055, auc: 0.9035\n",
      "epoch: 6800, loss: 0.264930, auc: 0.9025\n",
      "epoch: 7200, loss: 0.268502, auc: 0.8995\n",
      "epoch: 7600, loss: 0.269742, auc: 0.8985\n",
      "epoch: 8000, loss: 0.268952, auc: 0.9020\n",
      "epoch: 8400, loss: 0.269285, auc: 0.9010\n",
      "epoch: 8800, loss: 0.267064, auc: 0.9005\n",
      "epoch: 9200, loss: 0.268374, auc: 0.9015\n",
      "epoch: 9600, loss: 0.266412, auc: 0.9020\n",
      "epoch: 10000, loss: 0.268755, auc: 0.9015\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.Adam(net.parameters(),lr=1e-2)\n",
    "loss_func=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(10001):\n",
    "    out=net(x)\n",
    "    loss=loss_func(out,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%400==0:\n",
    "        prediction=torch.max(nn.functional.softmax(out,dim=1),1)[1]\n",
    "        pred_y=prediction.data.numpy().squeeze()\n",
    "        target_y=y.data.numpy()\n",
    "        auc=(sum(pred_y==target_y))/2000\n",
    "        print('epoch: {}, loss: {:4f}, auc: {:.4f}'.format(i,loss,auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
