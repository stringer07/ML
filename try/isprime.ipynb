{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1]) torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "primelist=[]\n",
    "for i in range(1,1001):\n",
    "    primelist.append(sympy.prime(i))\n",
    "x1=torch.tensor(primelist)[:,np.newaxis]\n",
    "y1=torch.ones(1000,1)\n",
    "print(np.shape(x1),np.shape(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1]) torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "nonprimelist=[]\n",
    "for i in range(1,100000):\n",
    "    if not sympy.isprime(i):\n",
    "        nonprimelist.append(i)\n",
    "    if len(nonprimelist)==1000:\n",
    "        break\n",
    "x2=torch.tensor(nonprimelist)[:,np.newaxis]\n",
    "y2=torch.zeros(1000,1)\n",
    "print(np.shape(x2),np.shape(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.cat((x1,x2),dim=0).type(torch.FloatTensor)\n",
    "y=torch.cat((y1,y2),dim=0).squeeze().long()\n",
    "x,y=Variable(x),Variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.layer1=nn.Sequential(nn.Linear(1,64),nn.Dropout(p=0.1),nn.LeakyReLU())\n",
    "        self.layer2=nn.Sequential(nn.Linear(64,64),nn.Dropout(p=0.1),nn.LeakyReLU())\n",
    "        self.layer3=nn.Sequential(nn.Linear(64,2),nn.LeakyReLU())\n",
    "    def forward(self,x):\n",
    "        #x=x.view(x.size()[0],-1)\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        return x\n",
    "net=Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.246590, auc: 0.4980\n",
      "epoch: 400, loss: 0.537577, auc: 0.5175\n",
      "epoch: 800, loss: 0.529179, auc: 0.5465\n",
      "epoch: 1200, loss: 0.520550, auc: 0.5655\n",
      "epoch: 1600, loss: 0.505802, auc: 0.6040\n",
      "epoch: 2000, loss: 0.366838, auc: 0.8550\n",
      "epoch: 2400, loss: 0.308962, auc: 0.8840\n",
      "epoch: 2800, loss: 0.302073, auc: 0.8845\n",
      "epoch: 3200, loss: 0.290500, auc: 0.8925\n",
      "epoch: 3600, loss: 0.290490, auc: 0.8895\n",
      "epoch: 4000, loss: 0.295206, auc: 0.8805\n",
      "epoch: 4400, loss: 0.282315, auc: 0.8950\n",
      "epoch: 4800, loss: 0.283334, auc: 0.8940\n",
      "epoch: 5200, loss: 0.282818, auc: 0.8940\n",
      "epoch: 5600, loss: 0.277425, auc: 0.8945\n",
      "epoch: 6000, loss: 0.285728, auc: 0.8900\n",
      "epoch: 6400, loss: 0.276010, auc: 0.8975\n",
      "epoch: 6800, loss: 0.287751, auc: 0.8860\n",
      "epoch: 7200, loss: 0.271791, auc: 0.8985\n",
      "epoch: 7600, loss: 0.280800, auc: 0.8910\n",
      "epoch: 8000, loss: 0.274130, auc: 0.8995\n",
      "epoch: 8400, loss: 0.271387, auc: 0.9015\n",
      "epoch: 8800, loss: 0.277034, auc: 0.8940\n",
      "epoch: 9200, loss: 0.277774, auc: 0.8955\n",
      "epoch: 9600, loss: 0.273267, auc: 0.8995\n",
      "epoch: 10000, loss: 0.280997, auc: 0.8890\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.Adam(net.parameters(),lr=1e-2)\n",
    "loss_func=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(10001):\n",
    "    out=net(x)\n",
    "    loss=loss_func(out,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%400==0:\n",
    "        prediction=torch.max(nn.functional.softmax(out,dim=1),1)[1]\n",
    "        pred_y=prediction.data.numpy().squeeze()\n",
    "        target_y=y.data.numpy()\n",
    "        auc=(sum(pred_y==target_y))/2000\n",
    "        print('epoch: {}, loss: {:4f}, auc: {:.4f}'.format(i,loss,auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
